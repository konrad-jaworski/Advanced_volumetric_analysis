# CNN-ViT vs Attention Unet for Volumetric Data Segmentation

## Overview

This repository presents the implementation, training, and evaluation of two deep learning models for volumetric data segmentation:

- A classic **3D U-Net**
- A custom hybrid model combining **CNN and Vision Transformer (CNN-ViT)**

The entire comparison, analysis, and visualization of results are documented in **`Main_notebook.ipynb`**.

---

## Highlights

- âœ… Successfully trained and evaluated two 3D models capable of processing **variable-length volumetric sequences**.
- âœ… Adapted both architectures to support **sequence depth flexibility**, which is critical for real-world 3D datasets.
- âœ… Developed a custom Transformer-based segmentation pipeline integrated with CNN-based feature extraction.
- âœ… Implemented metric evaluation including **Dice score, IoU, F1-score, Precision, and Recall**.
- âœ… Modular, well-documented PyTorch codebase with separate components for:
  - Feature extraction
  - Transformer attention blocks
  - Positional encoding and upsampling
  - Evaluation pipeline

---

## Dataset

Due to the lack of access to thermographic data, we used a publicly available **CT scan dataset** as a substitute:

**ğŸ—‚ Source**: [COVID-19 CT Scans â€” Kaggle](https://www.kaggle.com/datasets/andrewmvd/covid19-ct-scans)

- The dataset includes volumetric CT scans labeled for COVID-19 infection.
- Each scan was treated as a 3D volume input with variable depth to simulate sequences similar to thermographic recordings.

---

## Repository Structure

```bash
.
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ networks/
â”‚   â””â”€â”€ layers/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ train_cnn_vit.py
â”‚   â””â”€â”€ metrics.py
â”œâ”€â”€ checkpoints/
â”œâ”€â”€ data/
â”œâ”€â”€ Main_notebook.ipynb    â† Full training + evaluation workflow
â””â”€â”€ README.md
